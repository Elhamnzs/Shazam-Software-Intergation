{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np \n",
    "import pyaudio \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from scipy.signal import spectrogram\n",
    "import librosa \n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Audio\n",
    "\n",
    "\n",
    "import sounddevice as sd\n",
    "import wave\n",
    "\n",
    "\n",
    "from scipy.signal import find_peaks\n",
    "import hashlib\n",
    "\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fft = 2048\n",
    "hop_length = n_fft // 4 \n",
    "sr =  22050\n",
    "\n",
    "\n",
    "# Define the ROI size\n",
    "ROI_TIME = 0.5  # in seconds\n",
    "ROI_FREQ = 100  # in Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectrogram(y): \n",
    "\n",
    "    n_fft = 2048 #  Number of samples in each FFT window. Higher values improve frequency resolution but reduce time resolution\n",
    "    hop_length = n_fft // 4  # 512, The number of samples between successive FFT frames. Smaller values increase overlap, providing smoother time representation.\n",
    "\n",
    "    stft = librosa.stft(y, n_fft=n_fft, hop_length=hop_length)\n",
    "    spectrogram = np.abs(stft)\n",
    "    spectrogram_dB = librosa.amplitude_to_db(spectrogram, ref=np.max)\n",
    "\n",
    "    return spectrogram_dB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_peaks_spectrogram(spectrogram_dB): \n",
    "\n",
    "    peaks = []\n",
    "    for t in range(spectrogram_dB.shape[1]):  # Loop over time frames\n",
    "        \n",
    "        # Apply the threshold in dB, adjusting the factor if necessary\n",
    "        # threshold_dB = 0.5 * np.max(spectrogram_dB[:, t])  # threshold in dB\n",
    "        threshold_dB =  0.2*np.min(spectrogram_dB[:, t])  # threshold in dB\n",
    "        freq_peaks, _ = find_peaks(spectrogram_dB[:, t], height=threshold_dB)  # Apply threshold to dB values\n",
    "\n",
    "        for f in freq_peaks:\n",
    "            frequency = f * sr / n_fft  # Actual frequency in Hz\n",
    "            time_point = t * hop_length / sr  # Time in seconds\n",
    "            peaks.append((time_point, frequency))  # Store (time_in_seconds, frequency_bin)\n",
    "\n",
    "\n",
    "    peaks = np.array(peaks)\n",
    "    return peaks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate hash\n",
    "def generate_hash(fa, ta, fk, tk):\n",
    "    hash_input = f\"{fa}-{fk}-{tk-ta}\".encode('utf-8')\n",
    "    return hashlib.sha1(hash_input).hexdigest()\n",
    "\n",
    "# Select anchor points based on the highest amplitude within a certain region\n",
    "def select_anchor_points(peaks, spectrogram_dB, num_anchors=5):\n",
    "    anchor_points = []\n",
    "    for t in range(0, spectrogram_dB.shape[1], int(ROI_TIME * sr / hop_length)):\n",
    "        for f in range(0, spectrogram_dB.shape[0], int(ROI_FREQ * n_fft / sr)):\n",
    "\n",
    "            region_peaks = peaks[\n",
    "                (peaks[:, 0] >= t * hop_length / sr) & (peaks[:, 0] < (t + int(ROI_TIME * sr / hop_length)) * hop_length / sr) &\n",
    "                (peaks[:, 1] >= f * sr / n_fft) & (peaks[:, 1] < (f + int(ROI_FREQ * n_fft / sr)) * sr / n_fft)\n",
    "            ]\n",
    "            \n",
    "            if len(region_peaks) > 0:\n",
    "                max_peak = region_peaks[np.argmax(spectrogram_dB[region_peaks[:, 1].astype(int) * n_fft // sr, region_peaks[:, 0].astype(int) * sr // hop_length])]\n",
    "                anchor_points.append(max_peak)\n",
    "    return np.array(anchor_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hashes(anchor_points, peaks): \n",
    "\n",
    "    # List to store the hashes\n",
    "    hashes = []\n",
    "\n",
    "    # Iterate over each anchor point\n",
    "    for anchor in anchor_points:\n",
    "        ta, fa = anchor\n",
    "\n",
    "        # Define the ROI\n",
    "        roi_peaks = peaks[(peaks[:, 0] >= ta) & (peaks[:, 0] <= ta + ROI_TIME) & (peaks[:, 1] >= fa - ROI_FREQ) & (peaks[:, 1] <= fa + ROI_FREQ)]\n",
    "        \n",
    "        # Generate hashes for keypoints in the ROI\n",
    "        for keypoint in roi_peaks:\n",
    "            tk, fk = keypoint\n",
    "            if (tk, fk) != (ta, fa):  # Exclude the anchor point itself\n",
    "                hash_value = generate_hash(fa, ta, fk, tk)\n",
    "                hashes.append(((fa, fk, tk - ta), ta, hash_value))\n",
    "\n",
    "    return hashes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_hash_audio_file(file_path):\n",
    "\n",
    "    y_full, _ = librosa.load(file_path, sr=sr)\n",
    "    spectrogram_dB_full = spectrogram(y_full)\n",
    "    peaks_full= find_peaks_spectrogram(spectrogram_dB_full)\n",
    "    anchor_points_full = select_anchor_points(peaks_full, spectrogram_dB_full)\n",
    "    hashes_full = get_hashes(anchor_points_full, peaks_full)\n",
    "\n",
    "    return list(map(list, hashes_full))  # Ensure the hashes are serializable\n",
    "\n",
    "\n",
    "def generate_hash_audio(y_full):\n",
    "\n",
    "    spectrogram_dB_full = spectrogram(y_full)\n",
    "    peaks_full= find_peaks_spectrogram(spectrogram_dB_full)\n",
    "    anchor_points_full = select_anchor_points(peaks_full, spectrogram_dB_full)\n",
    "    hashes_full = get_hashes(anchor_points_full, peaks_full)\n",
    "\n",
    "    return list(map(list, hashes_full))  # Ensure the hashes are serializable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_hashes_for_database(database_folder):\n",
    "    song_hashes = {}\n",
    "    \n",
    "    for song_file in os.listdir(database_folder):\n",
    "        if song_file.endswith('.mp3'):\n",
    "            audio_file_path = os.path.join(database_folder, song_file)\n",
    "\n",
    "            print('generating hashes for : ', audio_file_path)\n",
    "            hashes = generate_hash_audio_file(audio_file_path)\n",
    "\n",
    "            print('number of hashes generated for : ', audio_file_path, 'is : ', len(hashes))\n",
    "            print('saving in dictionary with key = ', song_file)\n",
    "            song_hashes[song_file] = hashes\n",
    "\n",
    "    return song_hashes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_match(hashes): \n",
    "\n",
    "    with open('song_hashes.json', 'r') as f:\n",
    "        song_hashes = json.load(f)\n",
    "\n",
    "    # Extract the hash values from the full song hashes \n",
    "    hash_values_full = set(h[2] for h in hashes)\n",
    "\n",
    "    # Find the song with the most matches\n",
    "    best_match_song = None\n",
    "    max_matches = 0\n",
    "\n",
    "    for song, hashes in song_hashes.items():\n",
    "        hash_values = set(h[2] for h in hashes)\n",
    "        common_hashes = hash_values_full.intersection(hash_values)\n",
    "        num_matches = len(common_hashes)\n",
    "\n",
    "        print('current matches : ', num_matches)\n",
    "        \n",
    "        if num_matches > max_matches:\n",
    "            max_matches = num_matches\n",
    "            best_match_song = song\n",
    "\n",
    "\n",
    "\n",
    "    print(f\"The song with the most matches is: {best_match_song} with {max_matches} matches\")\n",
    "\n",
    "    return best_match_song, max_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_match2(hashes): \n",
    "    with open('song_hashes.json', 'r') as f:\n",
    "        song_hashes = json.load(f)\n",
    "\n",
    "    # Extract the hash values from the full song hashes \n",
    "    hash_values_full = {h[2] for h in hashes}\n",
    "\n",
    "    # Find the song with the most matches\n",
    "    best_match_song = None\n",
    "    best_match_score = -1  # Initialize the best match score\n",
    "\n",
    "    for song, song_hashes_list in song_hashes.items():\n",
    "        hash_values = {h2[2] for h2 in song_hashes_list}\n",
    "        common_hashes = hash_values_full.intersection(hash_values)\n",
    "        num_matches = len(common_hashes)\n",
    "        \n",
    "        # Calculate the total difference for the common hashes\n",
    "        differences = []  # List to store all differences for variance calculation\n",
    "        valid_matches = 0  # Count how many matches are valid\n",
    "\n",
    "        for h in hashes:  # Query hashes\n",
    "            for h2 in song_hashes_list:  # Song hashes\n",
    "                if h[2] == h2[2]:  # Check if the hash value matches\n",
    "                    # Ensure both hashes have at least 4 elements (the required parts of the hash)\n",
    "                    if len(h) > 2 and len(h2) > 2:  # Check that both h and h2 have at least 4 elements\n",
    "                        diff = abs(h[1] - h2[1])  # Calculate the difference in the second value (e.g., h[1])\n",
    "                        differences.append(diff)\n",
    "                        valid_matches += 1\n",
    "                    else:\n",
    "                        print(f\"Skipping hash pair with missing h[3]: {h}, {h2}\")\n",
    "\n",
    "        # If valid matches exist, adjust the score\n",
    "        if valid_matches > 0:\n",
    "            # Calculate variance of the differences\n",
    "            variance = sum((x - (sum(differences) / valid_matches)) ** 2 for x in differences) / valid_matches\n",
    "            match_score = num_matches - variance  # Adjust the score based on variance\n",
    "        else:\n",
    "            match_score = num_matches  # If no valid matches, just count the hash matches\n",
    "\n",
    "        print(f\"Current song: {song}, Matches: {num_matches}, Variance: {variance if valid_matches > 0 else 0}, Score: {match_score}\")\n",
    "\n",
    "        if match_score > best_match_score:\n",
    "            best_match_score = match_score\n",
    "            best_match_song = song\n",
    "\n",
    "    print(f\"The song with the most matches is: {best_match_song} with {num_matches} matches\")\n",
    "\n",
    "    return best_match_song, num_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_match3(hashes): \n",
    "    with open('song_hashes.json', 'r') as f:\n",
    "        song_hashes = json.load(f)\n",
    "\n",
    "    # Find the song with the most matches\n",
    "    best_match_song = None\n",
    "    best_match_score = -1  # Initialize the best match score\n",
    "\n",
    "    for song, song_hashes_list in song_hashes.items():\n",
    "        num_matches = 0\n",
    "        differences = []  # List to store all differences\n",
    "\n",
    "        for h in hashes:  # Query hashes\n",
    "            for h2 in song_hashes_list:  # Song hashes\n",
    "                if h[2] == h2[2]:  # Check if the hash value matches\n",
    "                    # Ensure both h and h2 have at least 3 elements (the required parts of the hash)\n",
    "                    if len(h) > 2 and len(h2) > 2:  # Ensure h and h2 have at least 3 elements\n",
    "                        diff = abs(h[1] - h2[1])  # Calculate the difference\n",
    "                        differences.append(diff)\n",
    "                        num_matches += 1\n",
    "                    else:\n",
    "                        # print(f\"Skipping hash pair with missing elements: {h}, {h2}\")\n",
    "                        continue\n",
    "\n",
    "        if num_matches > 0:\n",
    "            # Calculate variance of the differences\n",
    "            variance = np.var(differences)\n",
    "            # A lower variance indicates more consistency in the matches\n",
    "            match_score = num_matches - variance  # Adjust the score based on variance\n",
    "        else:\n",
    "            match_score = 0  # No matches found\n",
    "\n",
    "        print(f\"Current song: {song}, Matches: {num_matches}, Variance: {variance if num_matches > 0 else 0}, Score: {match_score}\")\n",
    "\n",
    "        if match_score > best_match_score:\n",
    "            best_match_score = match_score\n",
    "            best_match_song = song\n",
    "\n",
    "    print(f\"The song with the most matches is: {best_match_song} with {num_matches} matches\")\n",
    "\n",
    "    return best_match_song, num_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_match4(hashes): \n",
    "    with open('song_hashes.json', 'r') as f:\n",
    "        song_hashes = json.load(f)\n",
    "\n",
    "    # Find the song with the most matches\n",
    "    best_match_song = None\n",
    "    max_matches = 0\n",
    "    best_match_score = -1  # Initialize the best match score\n",
    "\n",
    "    for song, song_hashes_list in song_hashes.items():\n",
    "        num_matches = 0\n",
    "        differences = []  # List to store all differences\n",
    "\n",
    "        for h in hashes:  # Query hashes\n",
    "            for h2 in song_hashes_list:  # Song hashes\n",
    "                if h[2] == h2[2]:  # Check if the hash value matches\n",
    "                    # Ensure both h and h2 have at least 3 elements (the required parts of the hash)\n",
    "                    if len(h) > 2 and len(h2) > 2:  # Ensure h and h2 have at least 3 elements\n",
    "                        # Compare the second elements of the hashes (h[1] and h2[1])\n",
    "                        diff = abs(h[1] - h2[1])  # Difference between query and song hash\n",
    "                        differences.append(diff)\n",
    "                        num_matches += 1\n",
    "                    else:\n",
    "                        print(f\"Skipping hash pair with missing elements: {h}, {h2}\")\n",
    "\n",
    "        if num_matches > 0:\n",
    "            # Calculate variance of the differences\n",
    "            variance = np.var(differences)\n",
    "            # A lower variance indicates more consistency in the matches\n",
    "            match_score = num_matches - variance  # Adjust the score based on the variance\n",
    "        else:\n",
    "            match_score = 0  # No matches found\n",
    "\n",
    "        print(f\"Current song: {song}, Matches: {num_matches}, Variance: {variance if num_matches > 0 else 0}, Score: {match_score}\")\n",
    "\n",
    "        if match_score > best_match_score:\n",
    "            best_match_score = match_score\n",
    "            best_match_song = song\n",
    "\n",
    "    print(f\"The song with the most matches is: {best_match_song} with {max_matches} matches\")\n",
    "\n",
    "    return best_match_song, max_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating hashes for :  database\\01 Boss Bitch.mp3\n",
      "number of hashes generated for :  database\\01 Boss Bitch.mp3 is :  10105\n",
      "saving in dictionary with key =  01 Boss Bitch.mp3\n",
      "generating hashes for :  database\\bob-sinclar-world-hold-on-official-video (1).mp3\n",
      "number of hashes generated for :  database\\bob-sinclar-world-hold-on-official-video (1).mp3 is :  34726\n",
      "saving in dictionary with key =  bob-sinclar-world-hold-on-official-video (1).mp3\n",
      "generating hashes for :  database\\goodbye my lover.mp3\n",
      "number of hashes generated for :  database\\goodbye my lover.mp3 is :  40696\n",
      "saving in dictionary with key =  goodbye my lover.mp3\n",
      "generating hashes for :  database\\It's Going Down Now.mp3\n",
      "number of hashes generated for :  database\\It's Going Down Now.mp3 is :  51601\n",
      "saving in dictionary with key =  It's Going Down Now.mp3\n",
      "generating hashes for :  database\\ymca.mp3\n",
      "number of hashes generated for :  database\\ymca.mp3 is :  32584\n",
      "saving in dictionary with key =  ymca.mp3\n",
      "Hashes generated and saved to song_hashes.json\n"
     ]
    }
   ],
   "source": [
    "# generating database \n",
    "\n",
    "# Save the hashes to a JSON file\n",
    "song_hashes = generate_hashes_for_database('database')\n",
    "with open('song_hashes.json', 'w') as f:\n",
    "    json.dump(song_hashes, f, indent=4)\n",
    "\n",
    "print(\"Hashes generated and saved to song_hashes.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4504c2a03da4c1ca90a62c1c4ed5847",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Record', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1771c0ca1bdf4f8cac08c4f8e10626c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Play', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68924c31af0e4007850f693ac05ecbc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value=\"Click 'Record' to start recording.\")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DURATION = 20  # Duration in seconds\n",
    "\n",
    "# Widget for starting and stopping recording\n",
    "record_button = widgets.Button(description=\"Record\")\n",
    "play_button = widgets.Button(description=\"Play\")\n",
    "status_label = widgets.Label(value=\"Click 'Record' to start recording.\")\n",
    "\n",
    "# Variable to store the recorded audio\n",
    "recorded_audio = None\n",
    "\n",
    "def record_audio(change):\n",
    "    global recorded_audio\n",
    "    status_label.value = \"Recording...\"\n",
    "    try:\n",
    "        # Record audio\n",
    "        recorded_audio = sd.rec(int(DURATION * sr), samplerate=sr, channels=1, dtype=np.float32)\n",
    "        sd.wait()  # Wait until recording is finished\n",
    "        status_label.value = \"Recording complete! Click 'Play' to listen.\"\n",
    "    except Exception as e:\n",
    "        status_label.value = f\"Error: {str(e)}\"\n",
    "\n",
    "def play_audio(change):\n",
    "    if recorded_audio is not None:\n",
    "        # Play the recorded audio\n",
    "        sd.play(recorded_audio, sr)\n",
    "        sd.wait()  # Wait until playback is finished\n",
    "    else:\n",
    "        status_label.value = \"No audio recorded yet. Please record first.\"\n",
    "        print('type of audio: ', type(record_audio))\n",
    "\n",
    "# Link buttons to their functions\n",
    "record_button.on_click(record_audio)\n",
    "play_button.on_click(play_audio)\n",
    "\n",
    "\n",
    "# Display widgets\n",
    "display(record_button, play_button, status_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current matches :  4\n",
      "current matches :  6\n",
      "current matches :  22\n",
      "current matches :  12\n",
      "current matches :  9\n",
      "The song with the most matches is: goodbye my lover.mp3 with 22 matches\n"
     ]
    }
   ],
   "source": [
    "hashes = generate_hash_audio(recorded_audio.ravel())\n",
    "bestmatch, num_matches = find_best_match(hashes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current song: 01 Boss Bitch.mp3, Matches: 4, Variance: 792.880791647183, Score: -788.880791647183\n",
      "Current song: bob-sinclar-world-hold-on-official-video (1).mp3, Matches: 6, Variance: 1122.5532568422307, Score: -1116.5532568422307\n",
      "Current song: goodbye my lover.mp3, Matches: 22, Variance: 2251.3264743771747, Score: -2229.3264743771747\n",
      "Current song: It's Going Down Now.mp3, Matches: 12, Variance: 1035.0427038602252, Score: -1023.0427038602252\n",
      "Current song: ymca.mp3, Matches: 9, Variance: 1220.8564043579372, Score: -1211.8564043579372\n",
      "The song with the most matches is: None with 9 matches\n"
     ]
    }
   ],
   "source": [
    "# bestmatch, num_matches = find_best_match2(hashes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current song: 01 Boss Bitch.mp3, Matches: 0, Avg Diff: 0, Score: 0\n",
      "Current song: bob-sinclar-world-hold-on-official-video (1).mp3, Matches: 0, Avg Diff: 0, Score: 0\n",
      "Current song: goodbye my lover.mp3, Matches: 1, Avg Diff: 0.023219954648524777, Score: 0.9767800453514752\n",
      "Current song: It's Going Down Now.mp3, Matches: 0, Avg Diff: 0, Score: 0\n",
      "Current song: ymca.mp3, Matches: 0, Avg Diff: 0, Score: 0\n",
      "The song with the most matches is: goodbye my lover.mp3 with 0 matches\n"
     ]
    }
   ],
   "source": [
    "# bestmatch, num_matches = find_best_match3(hashes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current song: 01 Boss Bitch.mp3, Matches: 9, Variance: 792.880791647183, Score: -783.880791647183\n",
      "Current song: bob-sinclar-world-hold-on-official-video (1).mp3, Matches: 44, Variance: 1122.5532568422304, Score: -1078.5532568422304\n",
      "Current song: goodbye my lover.mp3, Matches: 62, Variance: 2251.326474377175, Score: -2189.326474377175\n",
      "Current song: It's Going Down Now.mp3, Matches: 38, Variance: 1035.0427038602252, Score: -997.0427038602252\n",
      "Current song: ymca.mp3, Matches: 20, Variance: 1220.856404357937, Score: -1200.856404357937\n",
      "The song with the most matches is: None with 0 matches\n"
     ]
    }
   ],
   "source": [
    "# bestmatch, num_matches = find_best_match4(hashes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
